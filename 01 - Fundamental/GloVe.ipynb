{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ztt8sl7bEa13"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__, torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqauiNSgEnl2",
        "outputId": "4aa3fa8a-d3f6-42c0-9dfd-23b4e63625b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.21.6', '1.13.1+cu116')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1IspXdsaErf_",
        "outputId": "429b87ed-f1f5-4a13-e366-9929002dcce1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data"
      ],
      "metadata": {
        "id": "HtAjAB5aEvz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining corpus\n",
        "\n",
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \n",
        "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\"]"
      ],
      "metadata": {
        "id": "7LLCLk4FExy5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "\n",
        "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
        "corpus_tokenized  # we called each of this as \"tokens\", NOT words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4v396j0E70v",
        "outputId": "c509677b-630f-4b8e-e33d-d9b2caab3aa1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'dog', 'animal'],\n",
              " ['cat', 'animal', 'dog']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numericalization\n",
        "\n",
        "# getting all the unique words\n",
        "# we want to flatten this (basically merge all list)\n",
        "\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocabs  = list(set(flatten(corpus_tokenized)))  # vocabs is a term defining all unique words your system know"
      ],
      "metadata": {
        "id": "-tlTWL18FIBs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning id to all these vocabs\n",
        "\n",
        "word2index = {v: idx for idx, v in enumerate(vocabs)}"
      ],
      "metadata": {
        "id": "-E33iAwIFX44"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD6Ns6cvO9-2",
        "outputId": "777f813f-208e-47ed-9149-e5e13601c052"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'animal': 0, 'apple': 1, 'banana': 2, 'cat': 3, 'dog': 4, 'fruit': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding <UNK>, which is a very normal token exists in the world\n",
        "\n",
        "vocabs.append('<UNK>')"
      ],
      "metadata": {
        "id": "-hp349hgPF3R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have a way to know what is the id of <UNK>\n",
        "\n",
        "word2index['<UNK>'] = 6"
      ],
      "metadata": {
        "id": "E9tKjoxaPNKE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating index2word dictionary\n",
        "   \n",
        "index2word = {v:k for k, v in word2index.items()}\n",
        "index2word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLNFLRLkPT7n",
        "outputId": "847dfadd-1826-4e56-94ab-c2b194f37488"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'animal',\n",
              " 1: 'apple',\n",
              " 2: 'banana',\n",
              " 3: 'cat',\n",
              " 4: 'dog',\n",
              " 5: 'fruit',\n",
              " 6: '<UNK>'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqqLiPqsPaZJ",
        "outputId": "8f91e138-b25d-4d72-a7a0-b149d32c92c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['animal', 'apple', 'banana', 'cat', 'dog', 'fruit', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Co-occurrence matrix"
      ],
      "metadata": {
        "id": "dnGazDJOPeiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using Counter to first count stuffs\n",
        "from collections import Counter\n",
        "\n",
        "# print(corpus_tokenized)\n",
        "\n",
        "# counting the frequency of each word....\n",
        "# we somehow need this to calculate the probability Pi\n",
        "X_i = Counter(flatten(corpus_tokenized)) # merging all list....(flatten is a function I define.....)\n",
        "\n",
        "# X_i['apple'] #get the probability of apple"
      ],
      "metadata": {
        "id": "L38brXnlPiGb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JhoMhNsQDc_",
        "outputId": "694b683d-4862-4f94-9f25-2a40a0d24b53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'dog', 'animal'],\n",
              " ['cat', 'animal', 'dog']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a skipgram of window size 1\n",
        "skip_grams = []\n",
        "\n",
        "# looping through each corpus\n",
        "for sent in corpus_tokenized:  #['apple', 'banana', 'fruit']\n",
        "    # looping through each word from 1 to n-1 (because 0 and n has no context window)\n",
        "    for i in range(1, len(sent)-1):\n",
        "        target  = sent[i]\n",
        "        context = [sent[i+1], sent[i-1]]\n",
        "        # appending(i, i+1) and (i, i-1)\n",
        "        for c in context:\n",
        "            skip_grams.append((target, c))"
      ],
      "metadata": {
        "id": "bewTahQsQG82"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjqP-VTXQZrP",
        "outputId": "7bfbc15a-cd6f-47e6-ff33-802048866ee4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'dog', 'animal'],\n",
              " ['cat', 'animal', 'dog']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1EtHKlLQgZt",
        "outputId": "6938a209-b77a-45dc-82b3-3ce9709955a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('banana', 'fruit'),\n",
              " ('banana', 'apple'),\n",
              " ('apple', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('fruit', 'banana'),\n",
              " ('cat', 'animal'),\n",
              " ('cat', 'dog'),\n",
              " ('dog', 'animal'),\n",
              " ('dog', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('animal', 'cat')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since we have these occurrences, we can count, to make our co-occurrence matrix!!!\n",
        "X_ik_skipgram = Counter(skip_grams)\n",
        "X_ik_skipgram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r-zS6-lQmQI",
        "outputId": "18cb6667-730c-41ba-d59e-71ecef73babb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('banana', 'fruit'): 1,\n",
              "         ('banana', 'apple'): 1,\n",
              "         ('apple', 'fruit'): 1,\n",
              "         ('apple', 'banana'): 1,\n",
              "         ('fruit', 'apple'): 1,\n",
              "         ('fruit', 'banana'): 1,\n",
              "         ('cat', 'animal'): 1,\n",
              "         ('cat', 'dog'): 1,\n",
              "         ('dog', 'animal'): 1,\n",
              "         ('dog', 'cat'): 1,\n",
              "         ('animal', 'dog'): 1,\n",
              "         ('animal', 'cat'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ik_skipgram[('banana', 'animal')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L3NPlaZQqlk",
        "outputId": "438474e8-8958-43d7-885d-9ddcb22ce485"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ik_skipgram[('banana', 'apple')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQ_nrZqQrBh",
        "outputId": "78dcb482-a260-4606-d010-8a410bf1e0d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighting Function f"
      ],
      "metadata": {
        "id": "6god_O7JQ6V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighting(w_i, w_j, X_ik):   # we need w_i and w_j, because we can try its co-occurrences, if it's too big, we scale it down\n",
        "    \n",
        "    # checking whether the co-occurrences between these two word exists???\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  # why one, so that the probability thingy won't break...(label smoothing)\n",
        "        \n",
        "    # maximum co-occurrences; we follow the paper\n",
        "    x_max = 100\n",
        "    alpha = 0.75\n",
        "    \n",
        "    # if the co-occurrences does not exceed x_max, scale it down based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max) ** alpha\n",
        "    else:\n",
        "        result = 1 # this is the maximum probability we can have\n",
        "        \n",
        "    return result"
      ],
      "metadata": {
        "id": "XdMPBQ2mQzDO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_i  = 'banana'\n",
        "w_j  = 'fruit'\n",
        "w_j2 = 'chaky'\n",
        "\n",
        "print(weighting(w_i, w_j, X_ik_skipgram))   # scales from 1 to 0.0316\n",
        "print(weighting(w_i, w_j2, X_ik_skipgram))  # the paper says that f(0) = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICGdKA3fRIq5",
        "outputId": "251d24ea-ebd9-4706-bc3c-cd0a0841f18e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03162277660168379\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkeDzb1DROEF",
        "outputId": "53be8050-9f44-4740-c9c8-08028477426e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['animal', 'apple', 'banana', 'cat', 'dog', 'fruit', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying this weighting to all possible pairs\n",
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {} # for keeping the co-occurrences\n",
        "weighting_dic = {} # for keeping all the probability after passing through the weighting function\n",
        "\n",
        "for bigram in combinations_with_replacement(vocabs, 2):  # we need to also think its reverse\n",
        "    # if this bigram exists in X_ik_skipgrams\n",
        "    # we gonna add this to our co-occurence matrix\n",
        "    if X_ik_skipgram.get(bigram) is not None:\n",
        "        cooc = X_ik_skipgram[bigram]  # getting the co-occurrence\n",
        "        X_ik[bigram] = cooc + 1 # this is again basically label smoothing....(stability issues (especially when divide something))\n",
        "        X_ik[(bigram[1], bigram[0])] = cooc + 1  # trick to get all pairs\n",
        "    else: # otherwise, do nothing\n",
        "        pass\n",
        "    \n",
        "    # applying the weighting function using this co-occurrence matrix thingy    \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)"
      ],
      "metadata": {
        "id": "lnPaUyXOROJ7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_ik_skipgram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6cQ_c4jROPY",
        "outputId": "9ff80fa7-90ae-4c15-ae27-3e195bd91f8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_ik"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xmBrilTROVH",
        "outputId": "8d501597-1d26-47aa-8a29-99d22609b7e6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('animal', 'cat'): 2,\n",
              " ('cat', 'animal'): 2,\n",
              " ('animal', 'dog'): 2,\n",
              " ('dog', 'animal'): 2,\n",
              " ('apple', 'banana'): 2,\n",
              " ('banana', 'apple'): 2,\n",
              " ('apple', 'fruit'): 2,\n",
              " ('fruit', 'apple'): 2,\n",
              " ('banana', 'fruit'): 2,\n",
              " ('fruit', 'banana'): 2,\n",
              " ('cat', 'dog'): 2,\n",
              " ('dog', 'cat'): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Train Data"
      ],
      "metadata": {
        "id": "z---697-Rxup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for c in corpus_tokenized:\n",
        "    print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UESz6cv6ROaY",
        "outputId": "2a933d6b-cf75-4d20-a9cd-b61cc8e7fb45"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'dog', 'animal']\n",
            "['cat', 'animal', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UBjUtkrbs7u",
        "outputId": "685e3b22-a9f7-472f-eb2c-cb49e1df6551"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('banana', 'fruit'),\n",
              " ('banana', 'apple'),\n",
              " ('apple', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('fruit', 'banana'),\n",
              " ('cat', 'animal'),\n",
              " ('cat', 'dog'),\n",
              " ('dog', 'animal'),\n",
              " ('dog', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('animal', 'cat')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    # looping through this skipgram, and changing it to id  because when sending model, it must have a number\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    # randomly picking \"batch_size\" indexes\n",
        "    number_of_choices = len(skip_grams_id)\n",
        "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) # no repeating indexes among these random indexes\n",
        "    \n",
        "    random_inputs = [] #xi, wi (in batches)\n",
        "    random_labels = [] #xj, wj (in batches)\n",
        "    random_coocs  = [] #Xij (in batches)\n",
        "    random_weighting = [] #f(Xij) (in batches)\n",
        "    # for each of the sample in these indexes\n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]]) # same reason why i put bracket here....\n",
        "        random_labels.append([skip_grams_id[i][1]])\n",
        "        \n",
        "        # getting cooc\n",
        "        # first checking whether it exists...\n",
        "        pair = skip_grams[i]  #e.g., ('banana', 'fruit)\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1 #label smoothing\n",
        "            \n",
        "        random_coocs.append([math.log(cooc)])  # 1. why log, # 2. why bracket -> size ==> (, 1)  # my neural network expects (, 1)\n",
        "        \n",
        "        # getting weighting\n",
        "        weighting = weighting_dic[pair]  # why not use try....maybe it does not exist....\n",
        "        random_weighting.append(weighting)\n",
        "\n",
        "        \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weighting)\n",
        "    "
      ],
      "metadata": {
        "id": "KOCJlU9ebtBR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)"
      ],
      "metadata": {
        "id": "KJTLyRzzbtGO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, target, cooc, weightin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN3TAgyucYAQ",
        "outputId": "4be72500-c383-46fa-a306-8fa742ce869b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1],\n",
              "        [2]]), array([[2],\n",
              "        [5]]), array([[0.69314718],\n",
              "        [0.69314718]]), array([0.05318296, 0.05318296]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "5mmYVWlhhhdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ],
      "metadata": {
        "id": "xWBYbQ0zhknV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "NcsleSEfjh2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = len(vocabs)\n",
        "batch_size = 2 # why?  no reason; \n",
        "emb_size = 2 # why?  no reason; usually 50, 100, 300, but 2 so we can plot (we can also plot 50, but we need to do PCA)\n",
        "model = GloVe(voc_size, emb_size)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "4iYfZkyhjjdJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5000\n",
        "# for epoch\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # getting random batch\n",
        "    input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch    = torch.LongTensor(input)\n",
        "    target_batch   = torch.LongTensor(target)\n",
        "    cooc_batch     = torch.FloatTensor(cooc)\n",
        "    weightin_batch = torch.FloatTensor(weightin)\n",
        "       \n",
        "    # print(input_batch.shape, label_batch.shape, cooc_batch.shape, weightin_batch)\n",
        "    \n",
        "    # loss = model\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weightin_batch)\n",
        "    \n",
        "    # backpropagation\n",
        "    loss.backward()\n",
        "    \n",
        "    # updating alpha\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing epoch loss\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: ??\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BOnWB5wnnpb",
        "outputId": "d394c584-6b7f-4482-c9c7-5482fe88038f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000 | Loss: 0.019917 | Time: ??\n",
            "Epoch 2000 | Loss: 0.106383 | Time: ??\n",
            "Epoch 3000 | Loss: 0.408712 | Time: ??\n",
            "Epoch 4000 | Loss: 0.026751 | Time: ??\n",
            "Epoch 5000 | Loss: 0.164411 | Time: ??\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the Embeddings"
      ],
      "metadata": {
        "id": "ECcUcyEREVeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHPztuxUn09f",
        "outputId": "bbaa7bc8-f25c-4c17-8249-06fe6e609e9a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['animal', 'apple', 'banana', 'cat', 'dog', 'fruit', '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "banana = torch.LongTensor([word2index['banana']])\n",
        "banana"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DB70zYuEb0p",
        "outputId": "7f6e8870-e013-4493-c3ff-c6cf6d1635f8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "banana_center_embed = model.embedding_v(banana)\n",
        "banana_outisde_embed = model.embedding_u(banana)\n",
        "\n",
        "banana_embed = (banana_center_embed + banana_outisde_embed) / 2\n",
        "banana_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2GGPtZfEb8q",
        "outputId": "501a255c-6efe-4e9b-b312-20b476294d3c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9469, -0.2703]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embed(word):\n",
        "  \n",
        "    try:\n",
        "        index = word2index[word]\n",
        "    except:\n",
        "        index = word2index['<UNK>']\n",
        "    \n",
        "    word = torch.LongTensor([index])\n",
        "\n",
        "    center_embed  = model.embedding_v(word)\n",
        "    outside_embed = model.embedding_u(word)\n",
        "    \n",
        "    embed = (center_embed + outside_embed) / 2\n",
        "    \n",
        "    return  embed[0][0].item(), embed[0][1].item()"
      ],
      "metadata": {
        "id": "68eSosUiEmHo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding embedding of fruit, cat\n",
        "\n",
        "print(get_embed('fruit'))\n",
        "print(get_embed('cat'))\n",
        "print(get_embed('chaky'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AJi3dzTEl35",
        "outputId": "b739f39f-727b-403e-af13-5a499ca05a24"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.2961082458496094, -0.7323914766311646)\n",
            "(-0.9956303834915161, 1.2956938743591309)\n",
            "(-0.09982331097126007, -0.2264615148305893)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting fruit cat banana on matplotlib\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "VuO5_E2YFGgD",
        "outputId": "94a71921-3992-4223-fb26-2762a41dc3c7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}