{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va_Eoqp58rJG",
        "outputId": "cad6cc1a-d02b-44f2-e4ae-e08d6b9303cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.25.1)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.26.14)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchdata) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkM-KCIJ-qxq",
        "outputId": "3be92bb0-8eb7-4e49-8278-34ad3412f7a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-02 11:00:22.002796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-02 11:00:22.890437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 11:00:22.890554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-02 11:00:22.890590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from de-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvBBYLhW2lOC",
        "outputId": "077cba29-be6e-463c-a618-5124cacf4d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NyqOZMg88mu0",
        "outputId": "0cbea4c4-56b4-41c9-bff5-7d36c8d5e2e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AYT_zVR_8moU",
        "outputId": "fc2b6803-90c4-41ee-b53b-9c49cec3cf96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2jt0W6lR9AMS",
        "outputId": "16b190ce-85d1-4d85-84fd-86ffc7505f0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ETL: Loading the Dataset"
      ],
      "metadata": {
        "id": "vMFeAQhD9DvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you are not using our department puffer\n",
        "import os\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TRG_LANGUAGE = 'de'\n",
        "\n",
        "train = Multi30k(split=('train'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))"
      ],
      "metadata": {
        "id": "KlLlP54Z9GKE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so this is a datapipe object; very similar to pytorch dataset version 2 which is better\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8PXbUyT9G1x",
        "outputId": "0d62f6b0-e387-4dee-8306-93cbac7ad8b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShardingFilterIterDataPipe"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. EDA - Simple Investigation"
      ],
      "metadata": {
        "id": "Zkk3-wsp-F6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at one example of train\n",
        "sample = next(iter(train))\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTVpBEYs9Gu_",
        "outputId": "ea911f85-924e-4083-b4e9-3e3c16a66d01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Two young, White males are outside near many bushes.',\n",
              " 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(list(iter(train)))\n",
        "train_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J2yoYra9Gjo",
        "outputId": "4df9b0ce-cfcd-4c8e-afda-7685af01bd48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29001"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, test = train.random_split(total_length=train_size, weights = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}, seed=999)"
      ],
      "metadata": {
        "id": "PA_gQjis-Jgl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(list(iter(train)))\n",
        "train_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD0ploew-Jaa",
        "outputId": "30409477-889a-4113-88be-7b3a2a5fec2c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20301"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = len(list(iter(val)))\n",
        "val_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKaASFEl-JUH",
        "outputId": "f3ba1ab7-0b6e-4de8-b877-c0832cbd5c02"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5800"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = len(list(iter(test)))\n",
        "test_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZHuw5qt-JFm",
        "outputId": "5c47d004-8e82-4039-dc29-3cdf8bf38e27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2900"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing"
      ],
      "metadata": {
        "id": "-9A0xcTj-Zc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "4ztmkNsv-cLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ],
      "metadata": {
        "id": "P6xCt3gD-gX_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')"
      ],
      "metadata": {
        "id": "_Sdpe5pZ-4aO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of tokenization of the english part\n",
        "print(\"Sentence: \", sample[0])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE](sample[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc2w0In3-4UK",
        "outputId": "d1fcd3a4-d5b0-4a2b-ef5c-f2feaf548722"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  Two young, White males are outside near many bushes.\n",
            "Tokenization:  ['Two', 'young', ',', 'White', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        yield token_transform[language](data_sample[language_index[language]]) # either first or second index"
      ],
      "metadata": {
        "id": "7kF57BkA-4KC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# making sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ],
      "metadata": {
        "id": "Xi0XWgtz_MCh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to Integers (Numericalization)"
      ],
      "metadata": {
        "id": "nXXTmuMa_Yek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # creating torchtext's vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
        "                                                    min_freq=2,   # if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)   # indicates whether to insert symbols at the beginning or at the end                                            \n",
        "# Setting UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "9EjWg9Dl_L6T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking some examples\n",
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCxEWXM4_Lzt",
        "outputId": "b69b5ff5-c81d-420c-a19a-2a723cb53e55"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1891, 10, 4, 0, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can reverse it....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "\n",
        "# printing 1816, for example\n",
        "mapping[1891]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EaX6rHG3BVpd",
        "outputId": "e7a34057-ece6-4c73-a3b3-511e137f948f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'here'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try unknown vocab\n",
        "mapping[0]\n",
        "# they will all map to <unk> which has 0 as integer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bxA-ZZG9BVkY",
        "outputId": "8aa8d9be-04c8-4a04-b9d3-dd1e63a016ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try special symbols\n",
        "mapping[1], mapping[2], mapping[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-mTZtDCBVdb",
        "outputId": "2511aa54-60e6-4b77-f821-537fc3e34aec"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking unique vocabularies\n",
        "len(mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oSzGIJ8BmDw",
        "outputId": "547e3ce0-1eb3-4e00-b62e-df136f25cc70"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5174"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preparing the DataLoader"
      ],
      "metadata": {
        "id": "ysAZjge4B9i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ],
      "metadata": {
        "id": "DUoBi0jmBl5i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "xnrCD2lPCHhx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for en, _, de in train_loader:\n",
        "    break"
      ],
      "metadata": {
        "id": "A7SjeyFbCKaT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"English shape: \", en.shape)  # (seq len, batch_size)\n",
        "print(\"German shape: \", de.shape)   # (seq len, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaF3g_3oCKTw",
        "outputId": "8ecc6d7b-69bb-417e-e4f7-e26eb0ffd9dd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape:  torch.Size([27, 64])\n",
            "German shape:  torch.Size([24, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Designing the Model"
      ],
      "metadata": {
        "id": "I53_aEYwCQ6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "At0aig1nCeXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim, bidirectional = True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        # src = [src len, batch size]\n",
        "        # src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        # need to explicitly put lengths on cpu!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'), enforce_sorted=False)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)        \n",
        "        # packed_outputs is a packed sequence containing all hidden states\n",
        "        # hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        # outputs is now a non-packed sequence, all hidden states obtained\n",
        "        # when the input is a pad token are all zeros\n",
        "            \n",
        "        # outputs = [src len, batch size, hid dim * num directions]\n",
        "        # hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        # outputs are always from the last layer\n",
        "        \n",
        "        # hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        # initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        # encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        # outputs = [src len, batch size, hid dim * 2]\n",
        "        # hidden = [batch size, hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "5M3FkFfCCVoz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "aN6ZFkI2C1Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        #hidden = [batch size, src len, hid dim]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n",
        "        #energy = [batch size, src len, hid dim]\n",
        "        \n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        #attention = [batch size, src len]\n",
        "        \n",
        "        #use masked_fill_ if you want in-place\n",
        "        attention = attention.masked_fill(mask, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "metadata": {
        "id": "SJFP44CQCWV8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of masked_fill\n",
        "# reall that 1 is pad_idx\n",
        "x = torch.tensor([ [9, 1, 7, 2, 1, 1], [99, 1, 1, 0, 8, 9] ])\n",
        "\n",
        "mask = (x == PAD_IDX)\n",
        "\n",
        "x.masked_fill_(mask, -1e10)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfjUwGlJCWJ9",
        "outputId": "9a362942-0719-40ec-d5bd-376ef172faed"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[           9, -10000000000,            7,            2, -10000000000,\n",
            "         -10000000000],\n",
            "        [          99, -10000000000, -10000000000,            0,            8,\n",
            "                    9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "igecHGQUDR2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "                \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        #weighted = [batch size, 1, hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        #weighted = [1, batch size, hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        #rnn_input = [1, batch size, (hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "               \n",
        "        prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "metadata": {
        "id": "QOV3NKUXDTXA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting them together (become Seq2Seq!)"
      ],
      "metadata": {
        "id": "j4Lz665DDrue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqPackedAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src == self.src_pad_idx).permute(1, 0)  #permute so it's the same shape as attention\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "                \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attentiont outputs from decoder\n",
        "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input_ = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
        "            #output    = [batch size, output dim]\n",
        "            #hidden    = [batch size, hid dim]\n",
        "            #attention = [batch size, src len]\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #place attentions in a tensor holding attention for each token\n",
        "            attentions[t] = attention\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input_ = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs, attentions"
      ],
      "metadata": {
        "id": "fDkVLxsVDlKZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Training"
      ],
      "metadata": {
        "id": "hDPgheTvEA4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ],
      "metadata": {
        "id": "gi9UBefoDk9n"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 256  \n",
        "hid_dim     = 512  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim)\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "model = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhvqCAfxDk2H",
        "outputId": "685c50d1-3d8f-4442-f072-142b79d8ed4d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5174, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(6433, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=6433, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qeDTbzUERGs",
        "outputId": "368073cc-2836-444e-b95d-b7ff545dc100"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324544\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "524288\n",
            "   512\n",
            "   512\n",
            "262144\n",
            "   512\n",
            "524288\n",
            "   512\n",
            "1646848\n",
            "1966080\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "11527936\n",
            "  6433\n",
            "______\n",
            "20939553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "# training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) # combining softmax with cross entropy"
      ],
      "metadata": {
        "id": "gf6Mn_rXEQ_G"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        # trg    = [trg len, batch size]\n",
        "        # output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        # the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        # trg    = [(trg len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        # clipping the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "F_Jij516EhI-"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    # turning off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            # trg    = [trg len, batch size]\n",
        "            # output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            # trg    = [(trg len - 1) * batch size]\n",
        "            # output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ],
      "metadata": {
        "id": "KFi2kG8bEhBt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting everything together"
      ],
      "metadata": {
        "id": "NMbytN0nFEt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ],
      "metadata": {
        "id": "WMzIeSvQEg7B"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "kon0DQ62FNLV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 10\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'{model.__class__.__name__}.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model, valid_loader, criterion, val_loader_length)\n",
        "    \n",
        "    # for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    \n",
        "    # lower perplexity is better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soLFluPUFNAp",
        "outputId": "10678975-d4d5-47cc-d4bb-e902b2b72409"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 20s\n",
            "\tTrain Loss: 3.056 | Train PPL:  21.234\n",
            "\t Val. Loss: 3.349 |  Val. PPL:  28.488\n",
            "Epoch: 02 | Time: 1m 20s\n",
            "\tTrain Loss: 2.637 | Train PPL:  13.974\n",
            "\t Val. Loss: 2.953 |  Val. PPL:  19.164\n",
            "Epoch: 03 | Time: 1m 19s\n",
            "\tTrain Loss: 2.321 | Train PPL:  10.186\n",
            "\t Val. Loss: 2.712 |  Val. PPL:  15.056\n",
            "Epoch: 04 | Time: 1m 18s\n",
            "\tTrain Loss: 2.067 | Train PPL:   7.898\n",
            "\t Val. Loss: 2.471 |  Val. PPL:  11.831\n",
            "Epoch: 05 | Time: 1m 19s\n",
            "\tTrain Loss: 1.867 | Train PPL:   6.466\n",
            "\t Val. Loss: 2.340 |  Val. PPL:  10.383\n",
            "Epoch: 06 | Time: 1m 19s\n",
            "\tTrain Loss: 1.710 | Train PPL:   5.530\n",
            "\t Val. Loss: 2.208 |  Val. PPL:   9.097\n",
            "Epoch: 07 | Time: 1m 19s\n",
            "\tTrain Loss: 1.588 | Train PPL:   4.895\n",
            "\t Val. Loss: 2.079 |  Val. PPL:   8.000\n",
            "Epoch: 08 | Time: 1m 20s\n",
            "\tTrain Loss: 1.471 | Train PPL:   4.355\n",
            "\t Val. Loss: 1.977 |  Val. PPL:   7.218\n",
            "Epoch: 09 | Time: 1m 18s\n",
            "\tTrain Loss: 1.374 | Train PPL:   3.950\n",
            "\t Val. Loss: 1.909 |  Val. PPL:   6.750\n",
            "Epoch: 10 | Time: 1m 19s\n",
            "\tTrain Loss: 1.294 | Train PPL:   3.648\n",
            "\t Val. Loss: 1.809 |  Val. PPL:   6.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ikmcUy0mFM0c",
        "outputId": "20ed2dd3-ae71-44f6-b4d6-8a62d504375e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoniPsJoOI2j",
        "outputId": "a60f9a10-ad4a-47a9-8934-241336e2bd5b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 1.798 | Test PPL:   6.036 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyv3YqZRONiB",
        "outputId": "52093c19-2df1-4bd1-81f7-bf69aa941c8d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5174, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(6433, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=6433, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Testing on Some Random News"
      ],
      "metadata": {
        "id": "5cYGYc2mOVTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4QxTcNajONTp",
        "outputId": "d3707988-6ff2-4ffe-c339-b78e19bcf9f1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Two young, White males are outside near many bushes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mIwsks85OkSF",
        "outputId": "b68de208-2050-4d11-8396-d1a01919ab45"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](sample[0]).to(device)\n",
        "src_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_dG1HGGOpFR",
        "outputId": "207792db-98c2-477f-c34b-1120ac0d1c54"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   19,   25,   15, 1069,  842,   17,   56,   84,  331, 1623,    5,\n",
              "           3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trg_text = text_transform[TRG_LANGUAGE](sample[1]).to(device)\n",
        "trg_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZRfVo7Oo7b",
        "outputId": "ca065c1d-ff56-4b5c-8ec6-18fe94384350"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,   21,   83,  262,   32,   89,   22,   91,    7,   16,  115,    0,\n",
              "        2893,    4,    3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = src_text.reshape(-1, 1)  # because batch_size is 1"
      ],
      "metadata": {
        "id": "8mS3vKf2Oo1O"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trg_text = trg_text.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "q4zWNUCZOz12"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_text.shape, trg_text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HphhZpScOzdO",
        "outputId": "5424c62c-ff7c-40a2-bd0c-b11c1559e917"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([13, 1]), torch.Size([15, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ],
      "metadata": {
        "id": "RoWr66bWO594"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model(src_text, text_length, trg_text, 0) # turn off teacher forcing"
      ],
      "metadata": {
        "id": "EHzoQv_GO528"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape # trg_len, batch_size, trg_output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb02fiyWPAYS",
        "outputId": "40047bff-4da5-4610-c65d-7d9d408af069"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 1, 6433])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output.squeeze(1)"
      ],
      "metadata": {
        "id": "cicnGTG9PAiF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH6FZqCoPWCD",
        "outputId": "4e893baa-6634-41ea-f320-91a3cd89398e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 6433])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[1:]\n",
        "output.shape # trg_len, trg_output_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDnIKWGCPdq3",
        "outputId": "05273e26-0ae8-4c5b-cd78-81bc935c9e91"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14, 6433])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_max = output.argmax(1) # returns max indices"
      ],
      "metadata": {
        "id": "N-RJHPtWPdiw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ROFY5HPpcu",
        "outputId": "0103f74a-4fbd-4fed-8655-4347201ca537"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  21,   83,    9,  262,   32,   89,   22,   91,    7,   16,  115,   24,\n",
              "        1948,    4], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()"
      ],
      "metadata": {
        "id": "_LZetMglPrOy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZg3QPNNPrIX",
        "outputId": "65fc8927-4ae1-4b4d-ec00-846dba6a9869"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zwei\n",
            "junge\n",
            ",\n",
            "weiße\n",
            "Männer\n",
            "sind\n",
            "im\n",
            "Freien\n",
            "in\n",
            "der\n",
            "Nähe\n",
            "von\n",
            "Büschen\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Attention"
      ],
      "metadata": {
        "id": "L-u2rfbmP2gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attentions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nQ16ZKXP6Ya",
        "outputId": "eed95c6c-3a6d-4bce-8b53-0757fd130cbf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 1, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE](sample[0]) + ['<eos>']\n",
        "src_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6e_t-40P6lb",
        "outputId": "3218c51f-8ece-4358-fbd0-acc57f6c5523"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'Two',\n",
              " 'young',\n",
              " ',',\n",
              " 'White',\n",
              " 'males',\n",
              " 'are',\n",
              " 'outside',\n",
              " 'near',\n",
              " 'many',\n",
              " 'bushes',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjbeUhQ2QCox",
        "outputId": "a0161c04-1283-4317-d1e5-1d75318edcf8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'Zwei',\n",
              " 'junge',\n",
              " ',',\n",
              " 'weiße',\n",
              " 'Männer',\n",
              " 'sind',\n",
              " 'im',\n",
              " 'Freien',\n",
              " 'in',\n",
              " 'der',\n",
              " 'Nähe',\n",
              " 'von',\n",
              " 'Büschen',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=10)\n",
        "    \n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence \n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "7XMzv0OLQCeo"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_attention(src_tokens, trg_tokens, attentions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "UTj1ouw0QPVi",
        "outputId": "b4242b21-0543-43e1-b1c6-b73422f7e090"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-77-b23710e830bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-77-b23710e830bc>:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}