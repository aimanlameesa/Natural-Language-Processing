{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK3xwZM0LQH_",
        "outputId": "87dd2983-ca7b-427c-fdaa-f2bc0e93355d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata==0.5.1\n",
            "  Downloading torchdata-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.5.1) (1.26.15)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchdata==0.5.1) (2.27.1)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.5.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->torchdata==0.5.1) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata==0.5.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata==0.5.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata==0.5.1) (3.4)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "Successfully installed portalocker-2.7.0 torchdata-0.5.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchdata\n",
        "!pip install torchdata==0.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9S61jk_cJ2-",
        "outputId": "77b882b4-83d8-402f-8e59-3a09a77cf40a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDk-pnqqF_YX",
        "outputId": "a5b04d97-8ec3-4d9f-f1b0-faae97bb7484"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTUKzT7o_a0p",
        "outputId": "b86d4292-b1d1-4eac-dcbf-d856a53cde05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-21 16:14:15.315454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-21 16:14:16.377243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-21 16:14:16.377373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-21 16:14:16.377396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-md==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (63.4.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0Pq7mXZ28gvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafa8b4a-36e7-41d5-a9e9-5591eeff88a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lm-GIkPpLIQv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e0aa3b2e-14ea-4c61-abd2-238650943648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "OaUrJFA5Ff0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8937a3b8-741b-4b93-c85a-70a2784bfadc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu116'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchtext.__version__"
      ],
      "metadata": {
        "id": "I6UJgBRGFonM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "896919c1-df0b-4c49-9516-ccd3dfb20f53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.14.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3TiQflZLvBo"
      },
      "source": [
        "# 1. Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Py7mQJ0wL05O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "7f6bd35ead2b47b093d6930cdb0697af",
            "d41a7108ddc349928d38139ea8a3e446",
            "70d827d24bf5481692e39dc3c04df421",
            "579e7ac1cd154fd0aa6d54d9b9a42448",
            "970b8c2ec34f4c359ae671ae7b91e236",
            "ecba3d66363246f69c1d23e604a6cb9f",
            "6fa8122586354ec28aa86c5b4bbb09d6",
            "1115bf2ffca14bb895d848da1bc22f41",
            "60193f5fe9b542679f9d21f8574ff509",
            "12151d8fe3364b8598f12abe5a6ab51e",
            "ee14920c64d047ce996e8f4222988da0",
            "b538d6e724f34d878ce52bbde690fc0b",
            "69616b606d2b4bddac2969644f87bc03",
            "3c6241f0042b4e7fa6d2e6627a241174",
            "a7a823ee6c3d419a8fd1f0eac8f49be2",
            "950dc9517bf9443c8196ff3392da5440",
            "92357cecc3a440eeb0ae9e1c1dcf6bc0",
            "4fdd9be8c12348b5976cfe9e57253ce7",
            "c55381b88be54567bbb600a38e4c9e67",
            "14d373f5f0db45bc89f50e6851a63c37",
            "75b8ad112c4c457383930bcae61e2d9c",
            "f181b4f6d04b46e9b0b4e2c263a900f5",
            "7833375395b042698aa3f67a92bbbdb1",
            "37f03ad21f8b4c419ac4373d60f9e9a5",
            "dba611978b5d4624a298530701cc8c2f",
            "af8cf97feb9644f7bebeab44e05876a3",
            "1d7cd4c7fee6422d8863665f3cfd3341",
            "52a1dfba8dc14c7e99689f8eba00f734",
            "0e97b43c75c44f0dab01c24c84578141",
            "0f48650c52954d35923fee42200e970f",
            "d251ee0e1ee14313ba9c3a07ac854e1f",
            "e8765c02ea244489bb8e45467e5e5569",
            "c4ff3d98dcde4b9997be44082dbc0d83",
            "b4dde304aeee444b8515bc12c96145d1",
            "307cab9b948c4a598e40991f48b22154",
            "1470aac7fbf74ac69e3eb45b4f378ca6",
            "9815750aa4e343249f3c1b4c20099293",
            "d5b4b49cc3db4a4ab6e7c4c58a6801e5",
            "703b67c72033483b8c680b4e86895032",
            "b8a56cfb45a04e938257adb3ae5194bc",
            "4a999b0ad73a4e6e8946ed2ddc63ebe2",
            "e7c08a00709247dca674612bbc3f9d9b",
            "40e467cd530b4c19acc7309ae8f7faac",
            "45d6c07961584a069b00a4c136ba09b6",
            "10891d7d202c4b6d8006aa14a12746c4",
            "6c75cf9f81024312a02dcd87b6c5e660",
            "f7f0b26713604a5da342812d8b249308",
            "d8012e316e974b318b2d163151c9485a",
            "061b940d66a44abb9717a62409723be0",
            "d7db5983e725446585aea8d7f84574ae",
            "30c1fd74eaec44f2bc4e35ebda15a119",
            "dd9fad3f124a4a88a43bc35d008ed95c",
            "52c1cfd029094445bde62c030fc66249",
            "07b6a9f4ab784e479edbca2d6990af5d",
            "c717065afc9844eebfed962af5c5cd92",
            "af06bdc5e80f42068e8c89721bf77de2",
            "ce15a98687934065a10c3cf290ee423f",
            "7794be37848d465ba14e0a43102dbdbe",
            "e88dc727f14e4672945d30daf6d91305",
            "758d313479284982bc149705df95bbc9",
            "8a7244da34744f208be6b1a61448e612",
            "269c0dec6fd64a10afdd54882ea8187a",
            "a32f3e153d154d6db4379d929c042fab",
            "9dc000fe6bbe472c9634296bbc3f8a7e",
            "64173ea180994451bd1a5e104d2482ca",
            "dabf5460bda647f6bbe3ff427fb6a204",
            "42db29c6ffc54b33829e320ba4af0f09",
            "818537cfead846489f2a76504c53b8f1",
            "127d5f7a209e4b0ca1d70f5d9729d8c4",
            "462fe956ee0a4ddf9d071ddebaef745f",
            "a58853fb4dbc43e4b6bd517e26ae837a",
            "0d33d7f96e5948c6b818417b51436298",
            "65f73ce42e254a52b9696777f9de834c",
            "0c65098aeef848159ef84539df41690b",
            "b608708a774d4cf183221532e2cd5e79",
            "64cff16048804c879fbf525b79f3dd45",
            "628c910f7e064f40b44370f2f839aee9"
          ]
        },
        "outputId": "f9ae742a-3212-4395-d9b8-12db722bdc79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/857 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f6bd35ead2b47b093d6930cdb0697af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset parquet/codeparrot--github-jupyter-code-to-text to /root/.cache/huggingface/datasets/codeparrot___parquet/codeparrot--github-jupyter-code-to-text-cf9b56d996fd17e1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b538d6e724f34d878ce52bbde690fc0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7833375395b042698aa3f67a92bbbdb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/56.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4dde304aeee444b8515bc12c96145d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10891d7d202c4b6d8006aa14a12746c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af06bdc5e80f42068e8c89721bf77de2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42db29c6ffc54b33829e320ba4af0f09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/codeparrot___parquet/codeparrot--github-jupyter-code-to-text-cf9b56d996fd17e1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/codeparrot___parquet/codeparrot--github-jupyter-code-to-text-cf9b56d996fd17e1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['repo_name', 'path', 'license', 'content'],\n",
            "    num_rows: 47452\n",
            "}) Dataset({\n",
            "    features: ['repo_name', 'path', 'license', 'content'],\n",
            "    num_rows: 11864\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "import datasets\n",
        "\n",
        "# using \"github jupyter code to text\" dataset\n",
        "train = datasets.load_dataset(\"codeparrot/github-jupyter-code-to-text\", split=\"train\")\n",
        "test = datasets.load_dataset(\"codeparrot/github-jupyter-code-to-text\", split=\"test\")\n",
        "print(train, test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvz1_P-lMWf5"
      },
      "source": [
        "# 2. EDA - Simple Investigation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['content'][10])"
      ],
      "metadata": {
        "id": "CTVT1aAKbRcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d44d8c-d1b0-4501-9053-d9fd93a71408"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import pylearn2.utils\n",
            "import pylearn2.config\n",
            "import theano\n",
            "import neukrill_net.dense_dataset\n",
            "import neukrill_net.utils\n",
            "import numpy as np\n",
            "%matplotlib inline\n",
            "import matplotlib.pyplot as plt\n",
            "import holoviews as hl\n",
            "%load_ext holoviews.ipython\n",
            "import sklearn.metrics\n",
            "\n",
            "cd ..\n",
            "\n",
            "settings = neukrill_net.utils.Settings(\"settings.json\")\n",
            "run_settings = neukrill_net.utils.load_run_settings(\n",
            "    \"run_settings/replicate_8aug.json\", settings, force=True)\n",
            "\n",
            "model = pylearn2.utils.serial.load(run_settings['alt_picklepath'])\n",
            "\n",
            "c = 'train_objective'\n",
            "channel = model.monitor.channels[c]\n",
            "\n",
            "\"\"\"\n",
            "Explanation: The following are the results we've got from online augmentation so far. Some bugs have been fixed by Scott since then so these might be redundant. If they're not redundant then they are very bad.\n",
            "Loading the pickle\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "plt.title(c)\n",
            "plt.plot(channel.example_record,channel.val_record)\n",
            "\n",
            "c = 'train_y_nll'\n",
            "channel = model.monitor.channels[c]\n",
            "plt.title(c)\n",
            "plt.plot(channel.example_record,channel.val_record)\n",
            "\n",
            "def plot_monitor(c = 'valid_y_nll'):\n",
            "    channel = model.monitor.channels[c]\n",
            "    plt.title(c)\n",
            "    plt.plot(channel.example_record,channel.val_record)\n",
            "    return None\n",
            "plot_monitor()\n",
            "\n",
            "plot_monitor(c=\"valid_objective\")\n",
            "\n",
            "\"\"\"\n",
            "Explanation: Replicating 8aug\n",
            "The DensePNGDataset run with 8 augmentations got us most of the way to our best score in one go. If we can replicate that results with online augmentation then we can be pretty confident that online augmentation is a good idea. Unfortunately, it looks like we can't:\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "%run check_test_score.py run_settings/replicate_8aug.json\n",
            "\n",
            "\"\"\"\n",
            "Explanation: Would actually like to know what kind of score this model gets on the check_test_score script.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "run_settings = neukrill_net.utils.load_run_settings(\n",
            "    \"run_settings/online_manyaug.json\", settings, force=True)\n",
            "\n",
            "model = pylearn2.utils.serial.load(run_settings['alt_picklepath'])\n",
            "\n",
            "plot_monitor(c=\"valid_objective\")\n",
            "\n",
            "\"\"\"\n",
            "Explanation: So we can guess that the log loss score we're seeing is in fact correct. There are definitely some bugs in the ListDataset code.\n",
            "Many Augmentations\n",
            "We want to be able to use online augmentations to run large combinations of different augmentations on the images. This model had almost everything turned on, a little:\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "settings = neukrill_net.utils.Settings(\"settings.json\")\n",
            "run_settings = neukrill_net.utils.load_run_settings(\n",
            "    \"run_settings/alexnet_based_onlineaug.json\", settings, force=True)\n",
            "\n",
            "model = pylearn2.utils.serial.load(run_settings['pickle abspath'])\n",
            "\n",
            "plot_monitor(c=\"train_y_nll\")\n",
            "\n",
            "plot_monitor(c=\"valid_y_nll\")\n",
            "\n",
            "plot_monitor(c=\"train_objective\")\n",
            "\n",
            "plot_monitor(c=\"valid_objective\")\n",
            "\n",
            "\"\"\"\n",
            "Explanation: Looks like it's completely incapable of learning.\n",
            "These problems suggest that the augmentation might be garbling the images; making them useless for learning from. Or worse, garbling the order so each image doesn't correspond to its label.\n",
            "Transformer Results\n",
            "We also have results from a network trained using a Transformer dataset, which is how online augmentation is supposed to be supported in Pylearn2.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test['content'][10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYjZgKzNbaRd",
        "outputId": "f71d7ebe-4f27-480b-a5ed-4ce1b8e20ff8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "%matplotlib inline\n",
            "\n",
            "from sklearn.preprocessing import Imputer\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.cross_validation import train_test_split as tts\n",
            "\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.svm import SVC \n",
            "\n",
            "from imblearn.over_sampling import SMOTE\n",
            "from imblearn.pipeline import Pipeline\n",
            "from sklearn.metrics import roc_curve, auc\n",
            "\n",
            "from __future__ import division\n",
            "import warnings\n",
            "warnings.filterwarnings(\"ignore\")\n",
            "\n",
            "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
            "secom = pd.read_table(url, header=None, delim_whitespace=True)\n",
            "\n",
            "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
            "y = pd.read_table(url, header=None, usecols=[0], squeeze=True, delim_whitespace=True)\n",
            "\n",
            "print 'The dataset has {} observations/rows and {} variables/columns.' \\\n",
            "       .format(secom.shape[0], secom.shape[1])\n",
            "print 'The ratio of majority class to minority class is {}:1.' \\\n",
            "      .format(int(y[y == -1].size/y[y == 1].size))\n",
            "\n",
            "\"\"\"\n",
            "Explanation: SVM classification/SMOTE oversampling for an imbalanced data set\n",
            "Date created: Oct 14, 2016 \n",
            "Last modified: Nov 16, 2016\n",
            "Tags: SVM, SMOTE, ROC/AUC, oversampling, imbalanced data set, semiconductor data \n",
            "About: Rebalance imbalanced semicondutor manufacturing dataset by oversampling the minority class using SMOTE. Classify using SVM. Assess the value of oversampling using ROC/AUC. \n",
            "<h3>I. Introduction</h3>\n",
            "\n",
            "The SECOM dataset in the  UCI Machine Learning Repository is semicondutor manufacturing data. There are 1567 records, 590 anonymized features and 104 fails. This makes it an imbalanced dataset with a 14:1 ratio of pass to fails. The process yield has a simple pass/fail response (encoded -1/1).\n",
            "<h4>Objective</h4>\n",
            "We consider some of the different approaches to classify imbalanced data. In the previous example we looked at one-class SVM.\n",
            "Another strategy is to rebalance the dataset by oversampling the minority class and/or undersampling the majority class. This is done to improve the sensitivity (i.e the true positive rate) of the minority class. For this exercise, we will look at: \n",
            "- rebalancing the dataset using SMOTE (which oversamples the minority class) \n",
            "- ROC curves for different oversampling ratios\n",
            "<h4>Methodology</h4>\n",
            "The sklearn imblearn toolbox has many methods for oversamplng/undersampling. We will use the SMOTE (Synthetic Minority Over-sampling Technique) method introduced in 2002 by Chawla et al. <a href=\"#ref1\">[1]</a>, <a href=\"#ref2\">[2]</a>. With SMOTE, synthetic examples are interpolated along the line segments joining some/all of the <i>k</i> minority class nearest neighbors.\n",
            "In the experiment, the  oversampling rate is varied between 10-70%, in 10% increments. The percentage represents the final minority class fraction after oversampling: if the majority class has 1000 data points (and the minority class 50), at 10% the minority class will have 100 data points after oversampling (not 5 or 50+5 = 55). \n",
            "The rebalanced data is classified using an SVM. The imblearn toolbox has a pipeline method which will be used to chain all the steps. The SMOTE+SVM method is evaluated by the area under the Receiver Operating Characteristic curve (AUC).\n",
            "<h4>Preprocessing</h4>\n",
            "The data represents measurements from a large number of processes or sensors and many of the records are missing. In addition some measurements are identical/constant and so not useful for prediction. We will remove those columns with high missing count or constant values.\n",
            "The Random Forest variable importance is used to rank the variables in terms of their importance. For the random forest, we will impute the remaining missing values with the median for the column. \n",
            "We will additionally scale the data that is applied to the SVM. We will use the <i>sklearn preprocessing</i> module for both imputing and scaling.\n",
            "These are the same steps used for the one-class SVM and a more detailed explanation can be seen there.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "# dropping columns which have large number of missing entries \n",
            "\n",
            "m = map(lambda x: sum(secom[x].isnull()), xrange(secom.shape[1]))\n",
            "m_200thresh = filter(lambda i: (m[i] > 200), xrange(secom.shape[1]))\n",
            "secom_drop_200thresh = secom.dropna(subset=[m_200thresh], axis=1)\n",
            "dropthese = [x for x in secom_drop_200thresh.columns.values if \\\n",
            "             secom_drop_200thresh[x].std() == 0]\n",
            "secom_drop_200thresh.drop(dropthese, axis=1, inplace=True)\n",
            "\n",
            "print 'The SECOM data set now has {} variables.'\\\n",
            "      .format(secom_drop_200thresh.shape[1])\n",
            "    \n",
            "\n",
            "# imputing missing values for the random forest\n",
            "\n",
            "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
            "secom_imp = pd.DataFrame(imp.fit_transform(secom_drop_200thresh))\n",
            "\n",
            "# use Random Forest to assess variable importance\n",
            "\n",
            "rf = RandomForestClassifier(n_estimators=100, random_state=7)\n",
            "rf.fit(secom_imp, y)\n",
            "\n",
            "# sorting features according to their rank\n",
            "\n",
            "importance = rf.feature_importances_\n",
            "ranked_indices = np.argsort(importance)[::-1]\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "Explanation: <h3>II. Preprocessing </h3>\n",
            "\n",
            "We process the missing values first, dropping columns which have a large number of missing values and imputing values for those that have only a few missing values.\n",
            "The Random Forest variable importance is used to rank the variables in terms of their importance. The one-class SVM exercise has a more detailed version of these steps.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "# split data into train and holdout sets\n",
            "# stratify the sample used for modeling to preserve the class proportions\n",
            "\n",
            "\n",
            "X_train, X_holdout, y_train, y_holdout = tts(secom_imp[ranked_indices[:40]], y, \\\n",
            "                                             test_size=0.2, stratify=y, random_state=5)\n",
            "\n",
            "\n",
            "print 'Train data: The majority/minority class have {} and {} elements respectively.'\\\n",
            "      .format(y_train[y_train == -1].size, y_train[y_train == 1].size)\n",
            "print 'The maj/min class ratio is: {0:2.0f}' \\\n",
            "      .format(round(y_train[y_train == -1].size/y_train[y_train == 1].size))\n",
            "print 'Holdout data: The majority/minority class have {} and {} elements respectively.'\\\n",
            "       .format(y_holdout[y_holdout == -1].size, y_holdout[y_holdout == 1].size)\n",
            "print 'The maj/min class ratio for the holdout set is: {0:2.0f}' \\\n",
            "      .format(round(y_holdout[y_holdout == -1].size/y_holdout[y_holdout == 1].size))\n",
            "    \n",
            "\n",
            "# scaling the split data. The holdout data uses scaling parameters \n",
            "# computed from the training data\n",
            "\n",
            "standard_scaler = StandardScaler()\n",
            "X_train_scaled  = pd.DataFrame(standard_scaler.fit_transform(X_train), \\\n",
            "                              index=X_train.index)\n",
            "X_holdout_scaled = pd.DataFrame(standard_scaler.transform(X_holdout))\n",
            "# Note: we convert to a DataFrame because the plot functions \n",
            "# we will use need DataFrame inputs.\n",
            "\n",
            "\"\"\"\n",
            "Explanation: <h3>III. SVM Classification </h3>\n",
            "\n",
            "<h4> Preprocessing </h4>\n",
            "\n",
            "The SVM is sensitive to feature scale so the first step is to center and normalize the data. The train and test sets are scaled separately using the mean and variance computed from the training data. This is done to estimate the ability of the model to generalize.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "# oversampling\n",
            "\n",
            "ratio = 0.5\n",
            "\n",
            "smote = SMOTE(ratio = ratio, kind='regular')\n",
            "smox, smoy = smote.fit_sample(X_train_scaled, y_train)\n",
            "\n",
            "print 'Before resampling: \\n\\\n",
            "The majority/minority class have {} and {} elements respectively.'\\\n",
            ".format(y_train[y == -1].size, y_train[y == 1].size)\n",
            "print 'After oversampling at {}%: \\n\\\n",
            "The majority/minority class have {} and {} elements respectively.'\\\n",
            ".format(ratio, smoy[smoy == -1].size, smoy[smoy == 1].size)\n",
            "\n",
            "\n",
            "# plotting minority class distribution after SMOTE\n",
            "# column 4 displayed\n",
            "\n",
            "from IPython.html.widgets import interact\n",
            "@interact(ratio=[0.1,1.0])\n",
            "\n",
            "def plot_dist(ratio):\n",
            "    sns.set(style=\"white\", font_scale=1.3) \n",
            "    fig, ax = plt.subplots(figsize=(7,5))\n",
            "\n",
            "    smote = SMOTE(ratio = ratio, kind='regular')\n",
            "    smox, smoy = smote.fit_sample(X_train_scaled, y_train)\n",
            "    smox_df = pd.DataFrame(smox)\n",
            "\n",
            "    ax = sns.distplot(smox_df[4][smoy == 1], color='b',  \\\n",
            "                  kde=False, label='after')         \n",
            "    ax = sns.distplot(X_train_scaled[4][y_train == 1], color='r', \\\n",
            "                  kde=False, label='before')\n",
            "    ax.set_ylim([0, 130])\n",
            "    ax.set(xlabel='')\n",
            "    ax.legend(title='Ratio = {}'.format(ratio))\n",
            "    plt.title('Minority class distribution before and after oversampling')\n",
            "\n",
            "    plt.show()\n",
            "\n",
            "\n",
            "# classification results\n",
            "\n",
            "from sklearn.metrics import confusion_matrix, matthews_corrcoef,\\\n",
            "classification_report, roc_auc_score, accuracy_score\n",
            "\n",
            "# manually selected parameters\n",
            "clf = SVC(C = 2, gamma = .0008)\n",
            "clf.fit(smox, smoy)\n",
            "y_predicted = clf.predict(X_holdout_scaled)\n",
            "\n",
            "\n",
            "print 'The accuracy is: {0:4.2} \\n' \\\n",
            ".format(accuracy_score(y_holdout, y_predicted))\n",
            "\n",
            "print 'The confusion matrix: '\n",
            "cm = confusion_matrix(y_holdout, y_predicted)\n",
            "print cm\n",
            "\n",
            "print '\\nThe True Negative rate is: {0:4.2}' \\\n",
            ".format(float(cm[1][1])/np.sum(cm[1]))\n",
            "\n",
            "print '\\nThe Matthews correlation coefficient: {0:4.2f} \\n' \\\n",
            ".format(matthews_corrcoef(y_holdout, y_predicted))\n",
            "\n",
            "print(classification_report(y_holdout, y_predicted))\n",
            "print 'The AUC is: {0:4.2}'\\\n",
            ".format(roc_auc_score(y_holdout, y_predicted))\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "Explanation: <h4> Finding parameters </h4>\n",
            "\n",
            "The usual way to select parameters is via grid-search and cross-validation (CV). The scoring is based on the accuracy. When the classes are imbalanced, the true positive of the majority class dominates. Often, there is a high cost associated with the misclassification of the minority class, and in those cases alternative scoring measures such as the F1 and $F_{\\beta}$ scores or the Matthews Correlation Coefficient (which uses all four values of the confusion matrix) are used. \n",
            "In CV experiments on this data, the majority class still dominates so that for the best CV F1-scores, the True Negative Rate (TNR - the rate at which the minority class is correctly classified) is zero.\n",
            "Instead of automating the selection of hyperparameters, I have manually selected <i>C</i> and $\\gamma$ values for which the precision/recall/F1 values as well as the TNR are high.\n",
            "An example is shown below.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "# oversampling, classification and computing ROC values\n",
            "\n",
            "fpr = dict()\n",
            "tpr = dict()\n",
            "roc_auc = dict()\n",
            "\n",
            "ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
            "C =     [3, 3, 3, 2, 2, 2, 2]\n",
            "gamma = [.02, .009, .009, .005, .0008, .0009, .0007]\n",
            "\n",
            "    \n",
            "estimators = [('smt', SMOTE(random_state=42)), \n",
            "              ('clf', SVC(probability=True, random_state=42))]\n",
            "pipe = Pipeline(estimators)\n",
            "\n",
            "print pipe\n",
            "\n",
            "for i, ratio, C, gamma in zip(range(7), ratio, C, gamma):\n",
            "\n",
            "    pipe.set_params(smt__ratio = ratio, clf__C = C, clf__gamma = gamma)\n",
            "    probas_ = pipe.fit(X_train_scaled, y_train).predict_proba(X_holdout_scaled)\n",
            "    fpr[i], tpr[i], _ = roc_curve(y_holdout, probas_[:,1])\n",
            "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
            "    \n",
            "\n",
            "# plotting the ROC curves\n",
            "\n",
            "def plot_roc(fpr, tpr, roc_auc):\n",
            "    colors = ['darkorange', 'deeppink', 'red', 'aqua', 'cornflowerblue','navy', 'blue']\n",
            "\n",
            "    plt.figure(figsize=(10,8.5))\n",
            "    for i, color in zip(range(7), colors):\n",
            "        plt.plot(fpr[i], tpr[i], color=color, lw=2, linestyle=':',\n",
            "                 label='{0} (area = {1:0.2f})'\n",
            "                 ''.format((i+1)/10, roc_auc[i]))\n",
            "\n",
            "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
            "    plt.xlim([0.0, 1.0])\n",
            "    plt.ylim([0.0, 1.05])\n",
            "    plt.xlabel('False Positive Rate')\n",
            "    plt.ylabel('True Positive Rate')\n",
            "    plt.title('ROC curves: SMOTE oversampled minority class', fontsize=14)\n",
            "    plt.legend(title='Class ratio after oversampling', loc=\"lower right\")\n",
            "    plt.show()\n",
            "    plt.savefig('ROC_oversampling.png')\n",
            "\n",
            "\n",
            "plot_roc(fpr, tpr, roc_auc)\n",
            "\n",
            "\"\"\"\n",
            "Explanation: For these manually selected parameters, the TNR is 0.38, the Matthews correlation coefficient is 0.21 and the precision/recall/F1 is in the 0.86 - 0.90 range. Selecting the best CV score (usually in the 0.90 range), on the other hand, would have given a TNR of 0 for all the scoring metrics I looked at.\n",
            "<h4>The Pipeline -- Oversampling, classification and ROC computations </h4>\n",
            "\n",
            "The imblearn package includes a pipeline module which allows one to chain transformers, resamplers and estimators. We compute the ROC curves for each of the oversampling ratios and corresponding hyperparameters C and gamma and for this we use the pipeline to oversample with SMOTE and classify with the SVM.\n",
            "End of explanation\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data.shape"
      ],
      "metadata": {
        "id": "6JgLFUU1Ka0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WHNAtdXNkZQ"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = [split for text in train['content'] for split in text.split('\\n') if split != \"\"]\n",
        "test_split = [split for text in test['content'] for split in text.split('\\n') if split != \"\"]"
      ],
      "metadata": {
        "id": "0DsxLfiEdbB1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of sentences\n",
        "len(train_split), len(test_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G8ShP2WOEDV",
        "outputId": "e65fe49b-7a18-4cf1-a25b-8ce7b1d0dc05"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11367363, 2875424)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AMIgPyCU_HkJ"
      },
      "outputs": [],
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def preprocessing(sentence):\n",
        "    \n",
        "    # removing the html tags and non-English words\n",
        "    sentence = re.sub(\"<[^>]*>\", \"\", sentence) \n",
        "    sentence = re.sub(\"[^\\x00-\\x7F]+\", \"\", sentence) \n",
        "    stopwords = list(STOP_WORDS)\n",
        "    doc = nlp(sentence)\n",
        "    cleaned_tokens = []\n",
        "    \n",
        "    # removing extra spaces or duplicate symbols.......\n",
        "    for token in doc: \n",
        "        if token.text not in stopwords and token.pos_ != 'PUNCT' and token.pos_ != 'SPACE' and \\\n",
        "            token.pos_ != 'SYM' and token.pos_!= 'X':\n",
        "                cleaned_tokens.append(token.lemma_.lower().strip())\n",
        "                \n",
        "    return \" \".join(cleaned_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IpdyFtRMYqQ"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lG5vasRiNdOh"
      },
      "outputs": [],
      "source": [
        "# tokenization\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter: \n",
        "        text = preprocessing(text)\n",
        "        yield tokenizer(text)\n",
        "\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "train_size = 100000\n",
        "test_size = 20000\n",
        "tokenized_dataset_train = yield_tokens(train_split[:train_size])\n",
        "tokenized_dataset_test = yield_tokens(test_split[:test_size])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence: \", train_split[0])\n",
        "# print(\"Tokenization: \", tokenized_dataset_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2TUwivldnoK",
        "outputId": "b1e4a4ba-1080-48bd-eafd-c0123348b02e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  import numpy as np\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_dataset_train = yield_tokens(train_split[:train_size])\n",
        "# tokenized_dataset_test = yield_tokens(test_split[:test_size])"
      ],
      "metadata": {
        "id": "sLHg9g6UscPk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_dataset_train[0]"
      ],
      "metadata": {
        "id": "8qmMXQF-sovY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ea1R8WRM91O3"
      },
      "outputs": [],
      "source": [
        "# tokenized_dataset_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1AvnpIBMt9X"
      },
      "source": [
        "### Numericalizing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# making sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ],
      "metadata": {
        "id": "JmbPtz7Vd-Fi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numericalization\n",
        "vocab = torchtext.vocab.build_vocab_from_iterator(yield_tokens(train_split[:train_size]), min_freq=3, specials=special_symbols)\n",
        "            \n",
        "vocab.set_default_index(vocab['<unk>'])   \n",
        "print(len(vocab))                         \n",
        "print(vocab.get_itos()[:10]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkU1vBkdOrOk",
        "outputId": "f0927b35-2633-4f08-cf75-519a8d4fd509"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11956\n",
            "['<unk>', '<pad>', '<sos>', '<eos>', '=', 'explanation', '#', 'end', \"'\", 'import']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Preparing Data"
      ],
      "metadata": {
        "id": "xh2W8sHseVIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(dataset, vocab, batch_size):\n",
        "    data = []                                                   \n",
        "    for example in dataset:       \n",
        "        # appending eos so we know it ends....so model learn how to end...                             \n",
        "        tokens = example.append('<eos>') # end of sentence\n",
        "        #numericalization     \n",
        "        tokens = [vocab[token] for token in example] \n",
        "        data.extend(tokens)                                    \n",
        "    data = torch.LongTensor(data)                                 \n",
        "    num_batches = data.shape[0] // batch_size # getting the int number of batches...\n",
        "    data = data[:num_batches * batch_size]    # making the batch evenly, and cut out any remaining                     \n",
        "    data = data.view(batch_size, num_batches)        \n",
        "    return data # [batch size, bunch of tokens]\n",
        "     "
      ],
      "metadata": {
        "id": "yaEw_YzltvJu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data"
      ],
      "metadata": {
        "id": "1YzR_laUiyQF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_data = get_data(tokenized_dataset_train, vocab, batch_size)\n",
        "valid_data = get_data(tokenized_dataset_test, vocab, batch_size)\n",
        "# test_data  = get_data(tokenized_dataset['test'], vocab, batch_size)"
      ],
      "metadata": {
        "id": "BP5IekqYflk5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader"
      ],
      "metadata": {
        "id": "YH9Jc-Iffla_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# saving train and valid data\n",
        "object_data = train_data\n",
        "file_train = open('train_data.pkl', 'wb') \n",
        "pickle.dump(object_data, file_train)\n",
        "\n",
        "object_data = valid_data\n",
        "file_val = open('valid_data.pkl', 'wb') \n",
        "pickle.dump(object_data, file_val)\n",
        "\n",
        "# saving vocab\n",
        "object_data = vocab\n",
        "file_vocab = open('vocab.pkl', 'wb') \n",
        "pickle.dump(object_data, file_vocab)"
      ],
      "metadata": {
        "id": "Hdkk78Dof5qJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0RQo5QBOBWD"
      },
      "source": [
        "# 5. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SabSvreOSFVk"
      },
      "source": [
        "## Mutli Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "tags": [],
        "id": "4IhbCpImGrNs"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        # query = [batch size, query len, hid dim]\n",
        "        # key = [batch size, key len, hid dim]\n",
        "        # value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        # Q = [batch size, query len, hid dim]\n",
        "        # K = [batch size, key len, hid dim]\n",
        "        # V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        # Q = [batch size, n heads, query len, head dim]\n",
        "        # K = [batch size, n heads, key len, head dim]\n",
        "        # V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        # energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "        # attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        # x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        # x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        # x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        # x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw_8ADPxSdGh"
      },
      "source": [
        "## Position-wise Feedforward Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "2ea4cff1-3c5e-408b-80fb-7d5d72875beb"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        # x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        # x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Yj2LmBzgGrNt"
      },
      "outputs": [],
      "source": [
        "class BeamSearchNode(object):\n",
        "    def __init__(self, previousNode, wordId, logProb, length):\n",
        "        self.prevNode = previousNode  # where does it come from\n",
        "        self.wordid   = wordId  #  numericalized integer of the word\n",
        "        self.logp     = logProb  # the log probability\n",
        "        self.len      = length  # the current length; first word starts at 1\n",
        "\n",
        "    def eval(self, alpha=0.7):\n",
        "        # the score will be simply the log probability penaltized by the length \n",
        "        # we are adding some small number to avoid division error\n",
        "        # read https://arxiv.org/abs/1808.10006 to understand how alpha is selected\n",
        "        return self.logp / float(self.len + 1e-6) ** (alpha)\n",
        "    \n",
        "    # this is the function for comparing between two beamsearchnodes, whether which one is better\n",
        "    # it is called when you called \"put\"\n",
        "    def __lt__(self, other):\n",
        "        return self.len < other.len\n",
        "\n",
        "    def __gt__(self, other):\n",
        "        return self.len > other.len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNuWcJJRQkT"
      },
      "source": [
        "## Decoder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "3AxHixSAGrNu"
      },
      "outputs": [],
      "source": [
        "from queue import PriorityQueue\n",
        "import operator\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, \n",
        "                 pf_dim, dropout, device, pad_idx, max_length = 100):\n",
        "                \n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "    \n",
        "        self.pad_idx = pad_idx\n",
        "    \n",
        "    def make_mask(self, x):\n",
        "        \n",
        "        # x = [batch size, len]\n",
        "        \n",
        "        pad_mask = (x != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        # pad_mask = [batch size, 1, 1, len]\n",
        "        \n",
        "        x_len = x.shape[1]\n",
        "        \n",
        "        sub_mask = torch.tril(torch.ones((x_len, x_len), device = self.device)).bool()\n",
        "        # sub_mask = [len, len]\n",
        "            \n",
        "        mask = pad_mask & sub_mask\n",
        "        # mask = [batch size, 1, len, len]\n",
        "        \n",
        "        return mask \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # x = [batch size, len]\n",
        "                \n",
        "        batch_size = x.shape[0]\n",
        "        x_len    = x.shape[1]\n",
        "        \n",
        "        # getting mask here since we remove seq2seq class\n",
        "        mask   = self.make_mask(x)\n",
        "        # mask = [batch size, 1, len, len]\n",
        "\n",
        "        pos = torch.arange(0, x_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)          \n",
        "            \n",
        "        x = self.dropout((self.tok_embedding(x) * self.scale) + self.pos_embedding(pos))\n",
        "        # x = [batch size, len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            x, attention = layer(x, mask)\n",
        "        \n",
        "        # x = [batch size, len, hid dim]\n",
        "        # attention = [batch size, n heads, len, len]\n",
        "        \n",
        "        output = self.fc_out(x)\n",
        "        # output = [batch size, len, output dim]\n",
        "            \n",
        "        return output, attention\n",
        "\n",
        "    def beam_decode(self, src_tensor, method='beam-search'):\n",
        "        \n",
        "        # src_tensor = [batch size, src len]\n",
        "        src_len = src_tensor.shape[1]\n",
        "        \n",
        "        # how many parallel searches\n",
        "        beam_width = 3\n",
        "        \n",
        "        # how many sentence do you want to generate\n",
        "        topk = 1  \n",
        "        \n",
        "        # final generated sentence\n",
        "        decoded_batch = []\n",
        "                                        \n",
        "        # starting with the start of the sentence token\n",
        "        decoder_input = torch.LongTensor([SOS_IDX]).to(device)\n",
        "\n",
        "        # number of sentences to generate\n",
        "        endnodes = []  # holding the nodes of EOS, so we can backtrack\n",
        "        number_required = min((topk + 1), topk - len(endnodes))\n",
        "\n",
        "        # starting node -  hidden vector, previous node, word id, logp, length\n",
        "        node = BeamSearchNode(None, decoder_input, 0, 1)\n",
        "        nodes = PriorityQueue()  # this is a min-heap\n",
        "\n",
        "        # starting the queue\n",
        "        nodes.put((-node.eval(), node))  # we need to put - because PriorityQueue is a min-heap\n",
        "        qsize = 1\n",
        "\n",
        "        # starting beam search\n",
        "        while True:\n",
        "            # giving up when decoding takes too long\n",
        "            if qsize > 100: break\n",
        "            \n",
        "            # print(f\"{nodes.queue=}\")\n",
        "\n",
        "            # fetching the best node\n",
        "            # the score is log p divides by the length scaled by some constants\n",
        "            score, n       = nodes.get()\n",
        "            decoder_input  = n.wordid\n",
        "\n",
        "            # getting all the previous nodes to construct a complete decoder input\n",
        "            # because Transformer decoder expects the whole sentence\n",
        "            prevNode = n.prevNode\n",
        "            while prevNode != None:\n",
        "                prev_word = torch.LongTensor([prevNode.wordid]).to(device)\n",
        "                # print(f\"{prev_word=}\")\n",
        "                decoder_input = torch.cat((decoder_input, prev_word))\n",
        "                prevNode = prevNode.prevNode\n",
        "\n",
        "            inv_idx       = torch.arange(decoder_input.size(0)-1, -1, -1).long()\n",
        "            decoder_input = decoder_input[inv_idx]\n",
        "\n",
        "            # wordid is simply the numercalized integer of the word\n",
        "            current_len    = n.len\n",
        "\n",
        "            decoder_input  = decoder_input.unsqueeze(0)\n",
        "            # decoder_input: batch_size, src_len\n",
        "\n",
        "            if n.wordid.item() == EOS_IDX and n.prevNode != None:\n",
        "                endnodes.append((score, n))\n",
        "                # if we reached maximum # of sentences required\n",
        "                if len(endnodes) >= number_required:\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            # decode for one step using decoder\n",
        "            # decoder_input = SOS_IDX\n",
        "            # mask = [1, src len]\n",
        "            decoder_input = F.pad(decoder_input, pad=(0, src_len), mode='constant', value=PAD_IDX)\n",
        "            # padding because our decoder expects a whole sentence, not one token by token....\n",
        "\n",
        "#             print(f\"{current_len=}\")\n",
        "#             print(f\"{decoder_input=}\")\n",
        "\n",
        "            prediction, _ = self.forward(decoder_input)\n",
        "            # prediction   = [batch size, src len, output dim]\n",
        "\n",
        "            prediction = prediction[:, current_len, :] # getting only the next word, but ignoring the padding\n",
        "            # prediction   = [batch size, output dim]\n",
        "\n",
        "            # so basically prediction is probabilities across all possible vocab\n",
        "            # we gonna retrieve k top probabilities (which is defined by beam_width) and their indexes\n",
        "            # we recall that beam_width defines how many parallel searches we want\n",
        "            log_prob, indexes = torch.topk(prediction, beam_width)\n",
        "            # log_prob      = (1, beam width)\n",
        "            # indexes       = (1, beam width)\n",
        "            \n",
        "            # print(f\"{log_prob.shape}\")\n",
        "            # print(f\"{indexes.shape}\")\n",
        "\n",
        "            nextnodes = []  # the next possible node we can move to\n",
        "\n",
        "            # we only select beam_width amount of nextnodes\n",
        "            for top in range(beam_width):\n",
        "                pred_t = indexes[0, top].reshape(-1)  # reshaping because wordid is assume to be []; see when we define SOS\n",
        "                log_p  = log_prob[0, top].item()\n",
        "\n",
        "                # decoder previous node, current node, prob, length\n",
        "                node = BeamSearchNode(n, pred_t, n.logp + log_p, n.len + 1)\n",
        "                score = -node.eval()\n",
        "                nextnodes.append((score, node))\n",
        "\n",
        "            # putting them into queue\n",
        "            for i in range(len(nextnodes)):\n",
        "                score, nn = nextnodes[i]\n",
        "                nodes.put((score, nn))\n",
        "                # increasing qsize\n",
        "            qsize += len(nextnodes) - 1\n",
        "\n",
        "\n",
        "        ### Once everything is finished, we choose nbest paths and back trace them.\n",
        "\n",
        "        ## in case it does not finish, we simply get couple of nodes with highest probability\n",
        "        if len(endnodes) == 0:\n",
        "            endnodes = [nodes.get() for _ in range(topk)]\n",
        "\n",
        "        # looking from the end and go back....\n",
        "        utterances = []\n",
        "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
        "            utterance = []\n",
        "            utterance.append(n.wordid)\n",
        "            # back tracing by looking at the previous nodes.....\n",
        "            while n.prevNode != None:\n",
        "                n = n.prevNode\n",
        "                utterance.append(n.wordid)\n",
        "\n",
        "            utterance = utterance[::-1]  # reversing it....\n",
        "            utterances.append(utterance) # appending to the list of sentences....\n",
        "\n",
        "        decoded_batch.append(utterances)\n",
        "\n",
        "        return decoded_batch  # (batch size, length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfPqcH8vRryP"
      },
      "source": [
        "## Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "8b6527fc-d6fb-4743-8905-1800d6bee652"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        \n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)        \n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        \n",
        "        # x = [batch size, len, hid dim]\n",
        "        # mask = [batch size, 1, len, len]\n",
        "        \n",
        "        # multi attention, skip and then norm\n",
        "        _x, attention = self.self_attention(x, x, x, mask)\n",
        "        x = self.self_attn_layer_norm(x + self.dropout(_x))\n",
        "        # x = [batch size, len, hid dim]\n",
        "        # attention = [batch size, n heads, len, len]\n",
        "    \n",
        "        # positionwise feedforward\n",
        "        _x = self.positionwise_feedforward(x)\n",
        "        x = self.ff_layer_norm(x + self.dropout(_x))\n",
        "        # x = [batch size, len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9jtPv_aOkdS"
      },
      "source": [
        "# 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "metadata": {
        "id": "PTu_OHZxmvY6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "o0EKjDjROujO"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "hid_dim    = 256                \n",
        "dec_layers = 3               \n",
        "dec_heads  = 8\n",
        "dec_pf_dim = 512\n",
        "dec_dropout = 0.1     \n",
        "lr = 1e-3   \n",
        "model = Decoder(vocab_size, hid_dim, dec_layers, dec_heads, dec_pf_dim, dec_dropout, device, PAD_IDX).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print the complexity by the number of parameters\n",
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(model)"
      ],
      "metadata": {
        "id": "8PASZGr8oEkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ab57ca-1cf3-4809-83be-680d795624e0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3060736\n",
            " 25600\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            " 65536\n",
            "   256\n",
            "131072\n",
            "   512\n",
            "131072\n",
            "   256\n",
            "3060736\n",
            " 11956\n",
            "______\n",
            "7740340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "oVMuX6E1UDsF"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.0005\n",
        "\n",
        "# training hyperparameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss() # combining softmax with cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, seq_len, idx):\n",
        "    # data # [batch size, bunch of tokens]\n",
        "    src    = data[:, idx:idx+seq_len]                   \n",
        "    target = data[:, idx+1:idx+seq_len+1]  # target simply is ahead of src by 1            \n",
        "    return src, target"
      ],
      "metadata": {
        "id": "huVb4rAVJjTp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9d7499dc-986d-4b46-8c04-fa0c4cd38d43"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    # droping all batches that are not a multiple of seq_len\n",
        "    # data # [batch size, bunch of tokens]\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]  # we need to add -1 because we start at 0\n",
        "    num_batches = data.shape[-1]\n",
        "        \n",
        "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        src, target = get_batch(data, seq_len, idx) # src, target: [batch size, seq len]\n",
        "        src, target = src.to(device), target.to(device)\n",
        "        batch_size = src.shape[0]\n",
        "        prediction, _ = model(src)               \n",
        "\n",
        "        # we need to reshape because criterion expects pred to be 2d and target to be 1d\n",
        "        prediction = prediction.reshape(batch_size * seq_len, -1)  # prediction: [batch size * seq len, vocab size]  \n",
        "        target = target.reshape(-1)\n",
        "        loss = criterion(prediction, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / (num_batches + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "0SJBv3vSGrNz"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "    \n",
        "    decoded_batch_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            src, target = get_batch(data, seq_len, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            \n",
        "            # target = [batch size, dec len]\n",
        "\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, _ = model(src)\n",
        "            # prediction = [batch size, dec len, output_dim]\n",
        "            \n",
        "            # decoding using beam_search as example (here beam_search is for intference)\n",
        "            decoded_batch = model.beam_decode(src, method='beam-search')\n",
        "            # print(decoded_batch)\n",
        "            \n",
        "            # len(decoded_batch) = 64\n",
        "            # len(decoded_batch[0]) = 1 = number of sentence generated, i.e., topk            \n",
        "            decoded_batch_list.append(decoded_batch)\n",
        "            \n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "\n",
        "            # print(vocab)\n",
        "            # print(type(vocab))\n",
        "            \n",
        "        # this is optional; printing first three samples of the first batch\n",
        "        print(\"Printing samples from first decode batch:\")\n",
        "\n",
        "        for sentence_index in decoded_batch_list[0][:3]:\n",
        "            # decode_text_arr = [vocab.lookup_token(i) for i in sentence_index[0]]\n",
        "            # decode_text_arr = [vocab.itos[i.item()] for i in sentence_index[0]]\n",
        "            # decode_sentence = \" \".join(decode_text_arr)\n",
        "            decode_text_arr = [vocab.lookup_token(i) for i in sentence_index[0]]\n",
        "            decode_sentence = \" \".join(decode_text_arr)\n",
        "            print(\"pred target : {}\".format(decode_sentence))\n",
        "            \n",
        "    return epoch_loss / (num_batches + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting everything together"
      ],
      "metadata": {
        "id": "aAlAEhyPo7NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "wyd72RQKORVk"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "a5a351f8-d2f5-4a7d-98ef-5fb2b0698a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8cc7a0-ad00-413e-bc5f-4ff8f1871459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing samples from first decode batch:\n",
            "pred target : <sos> <eos>\n",
            "Epoch: 01 | Time: 0m 9s\n",
            "\tTrain Perplexity: 203.200\n",
            "\tValid Perplexity: 97.628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing samples from first decode batch:\n",
            "pred target : <sos> <eos>\n",
            "Epoch: 02 | Time: 0m 8s\n",
            "\tTrain Perplexity: 106.499\n",
            "\tValid Perplexity: 85.935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing samples from first decode batch:\n",
            "pred target : <sos> <eos>\n",
            "Epoch: 03 | Time: 0m 8s\n",
            "\tTrain Perplexity: 76.305\n",
            "\tValid Perplexity: 81.911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing samples from first decode batch:\n",
            "pred target : <sos> <eos>\n",
            "Epoch: 04 | Time: 0m 8s\n",
            "\tTrain Perplexity: 58.504\n",
            "\tValid Perplexity: 80.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing samples from first decode batch:\n",
            "pred target : <sos> <eos>\n",
            "Epoch: 05 | Time: 0m 9s\n",
            "\tTrain Perplexity: 47.275\n",
            "\tValid Perplexity: 81.790\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "seq_len  = 10 # <----decoding length\n",
        "clip    = 0.25\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_data, optimizer, criterion, \n",
        "                batch_size, seq_len, clip, device)\n",
        "    valid_loss = evaluate(model, valid_data, criterion, batch_size, \n",
        "                seq_len, device)\n",
        "\n",
        "    lr_scheduler.step(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-tr_lm.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')\n",
        "      \n",
        "    # lower perplexity is better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juzLHplaYj4J"
      },
      "source": [
        "# 7. Real-world inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Ued57WHHYgwf"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, device, seed=None):\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    model.eval()\n",
        "    tokens = tokenizer(prompt)\n",
        "    indices = [vocab[t] for t in tokens]\n",
        "    batch_size = 1\n",
        "    with torch.no_grad():\n",
        "        for i in range(max_seq_len):\n",
        "            src = torch.LongTensor([indices]).to(device)\n",
        "            prediction, _ = model(src)\n",
        "            \n",
        "            # prediction: [batch size, seq len, vocab size]\n",
        "            # prediction[:, -1]: [batch size, vocab size] # probability of last vocab\n",
        "            \n",
        "            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)  \n",
        "            prediction = torch.multinomial(probs, num_samples=1).item()    \n",
        "            \n",
        "            while prediction == vocab['<unk>']: #if it is unk, we sample again\n",
        "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            if prediction == vocab['<eos>']:    #if it is eos, we stop\n",
        "                break\n",
        "\n",
        "            indices.append(prediction) #autoregressive, thus output becomes input\n",
        "            \n",
        "            #####################################################################\n",
        "            # only pure sampling is done....\n",
        "            # comparing with top-k, top-p, and beam search can be done here\n",
        "            #####################################################################\n",
        "\n",
        "    itos = vocab.get_itos()\n",
        "    tokens = [itos[i] for i in indices]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'import numpy '\n",
        "max_seq_len = 30\n",
        "seed = 0\n",
        "\n",
        "# smaller the temperature, more diverse tokens but comes with a tradeoff of less-make-sense sentence\n",
        "\n",
        "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
        "for temperature in temperatures:\n",
        "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer, \n",
        "                          vocab, device, seed)\n",
        "    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"
      ],
      "metadata": {
        "id": "oA2PS1G_iGZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb040b2-cd0f-4775-b370-ff034bb388dd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "import numpy np\n",
            "\n",
            "0.7\n",
            "import numpy np\n",
            "\n",
            "0.75\n",
            "import numpy np\n",
            "\n",
            "0.8\n",
            "import numpy np\n",
            "\n",
            "1.0\n",
            "import numpy np\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'import tensorflow '\n",
        "max_seq_len = 30\n",
        "seed = 0\n",
        "\n",
        "#smaller the temperature, more diverse tokens but comes \n",
        "#with a tradeoff of less-make-sense sentence\n",
        "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
        "for temperature in temperatures:\n",
        "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer, \n",
        "                          vocab, device, seed)\n",
        "    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtOxHoePZg4",
        "outputId": "dfe0eae7-f7f0-4f90-c42d-e51205d8ce74"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "import tensorflow tf\n",
            "\n",
            "0.7\n",
            "import tensorflow\n",
            "\n",
            "0.75\n",
            "import tensorflow\n",
            "\n",
            "0.8\n",
            "import tensorflow\n",
            "\n",
            "1.0\n",
            "import tensorflow\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f6bd35ead2b47b093d6930cdb0697af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d41a7108ddc349928d38139ea8a3e446",
              "IPY_MODEL_70d827d24bf5481692e39dc3c04df421",
              "IPY_MODEL_579e7ac1cd154fd0aa6d54d9b9a42448"
            ],
            "layout": "IPY_MODEL_970b8c2ec34f4c359ae671ae7b91e236"
          }
        },
        "d41a7108ddc349928d38139ea8a3e446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecba3d66363246f69c1d23e604a6cb9f",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa8122586354ec28aa86c5b4bbb09d6",
            "value": "Downloading readme: 100%"
          }
        },
        "70d827d24bf5481692e39dc3c04df421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1115bf2ffca14bb895d848da1bc22f41",
            "max": 857,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60193f5fe9b542679f9d21f8574ff509",
            "value": 857
          }
        },
        "579e7ac1cd154fd0aa6d54d9b9a42448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12151d8fe3364b8598f12abe5a6ab51e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee14920c64d047ce996e8f4222988da0",
            "value": " 857/857 [00:00&lt;00:00, 31.3kB/s]"
          }
        },
        "970b8c2ec34f4c359ae671ae7b91e236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecba3d66363246f69c1d23e604a6cb9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa8122586354ec28aa86c5b4bbb09d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1115bf2ffca14bb895d848da1bc22f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60193f5fe9b542679f9d21f8574ff509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12151d8fe3364b8598f12abe5a6ab51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee14920c64d047ce996e8f4222988da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b538d6e724f34d878ce52bbde690fc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69616b606d2b4bddac2969644f87bc03",
              "IPY_MODEL_3c6241f0042b4e7fa6d2e6627a241174",
              "IPY_MODEL_a7a823ee6c3d419a8fd1f0eac8f49be2"
            ],
            "layout": "IPY_MODEL_950dc9517bf9443c8196ff3392da5440"
          }
        },
        "69616b606d2b4bddac2969644f87bc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92357cecc3a440eeb0ae9e1c1dcf6bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_4fdd9be8c12348b5976cfe9e57253ce7",
            "value": "Downloading data files: 100%"
          }
        },
        "3c6241f0042b4e7fa6d2e6627a241174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55381b88be54567bbb600a38e4c9e67",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14d373f5f0db45bc89f50e6851a63c37",
            "value": 2
          }
        },
        "a7a823ee6c3d419a8fd1f0eac8f49be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b8ad112c4c457383930bcae61e2d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_f181b4f6d04b46e9b0b4e2c263a900f5",
            "value": " 2/2 [00:09&lt;00:00,  4.33s/it]"
          }
        },
        "950dc9517bf9443c8196ff3392da5440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92357cecc3a440eeb0ae9e1c1dcf6bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fdd9be8c12348b5976cfe9e57253ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c55381b88be54567bbb600a38e4c9e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d373f5f0db45bc89f50e6851a63c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75b8ad112c4c457383930bcae61e2d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f181b4f6d04b46e9b0b4e2c263a900f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7833375395b042698aa3f67a92bbbdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37f03ad21f8b4c419ac4373d60f9e9a5",
              "IPY_MODEL_dba611978b5d4624a298530701cc8c2f",
              "IPY_MODEL_af8cf97feb9644f7bebeab44e05876a3"
            ],
            "layout": "IPY_MODEL_1d7cd4c7fee6422d8863665f3cfd3341"
          }
        },
        "37f03ad21f8b4c419ac4373d60f9e9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a1dfba8dc14c7e99689f8eba00f734",
            "placeholder": "​",
            "style": "IPY_MODEL_0e97b43c75c44f0dab01c24c84578141",
            "value": "Downloading data: 100%"
          }
        },
        "dba611978b5d4624a298530701cc8c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f48650c52954d35923fee42200e970f",
            "max": 226542908,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d251ee0e1ee14313ba9c3a07ac854e1f",
            "value": 226542908
          }
        },
        "af8cf97feb9644f7bebeab44e05876a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8765c02ea244489bb8e45467e5e5569",
            "placeholder": "​",
            "style": "IPY_MODEL_c4ff3d98dcde4b9997be44082dbc0d83",
            "value": " 227M/227M [00:04&lt;00:00, 48.7MB/s]"
          }
        },
        "1d7cd4c7fee6422d8863665f3cfd3341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a1dfba8dc14c7e99689f8eba00f734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e97b43c75c44f0dab01c24c84578141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f48650c52954d35923fee42200e970f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d251ee0e1ee14313ba9c3a07ac854e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8765c02ea244489bb8e45467e5e5569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ff3d98dcde4b9997be44082dbc0d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4dde304aeee444b8515bc12c96145d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_307cab9b948c4a598e40991f48b22154",
              "IPY_MODEL_1470aac7fbf74ac69e3eb45b4f378ca6",
              "IPY_MODEL_9815750aa4e343249f3c1b4c20099293"
            ],
            "layout": "IPY_MODEL_d5b4b49cc3db4a4ab6e7c4c58a6801e5"
          }
        },
        "307cab9b948c4a598e40991f48b22154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703b67c72033483b8c680b4e86895032",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a56cfb45a04e938257adb3ae5194bc",
            "value": "Downloading data: 100%"
          }
        },
        "1470aac7fbf74ac69e3eb45b4f378ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a999b0ad73a4e6e8946ed2ddc63ebe2",
            "max": 56919709,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7c08a00709247dca674612bbc3f9d9b",
            "value": 56919709
          }
        },
        "9815750aa4e343249f3c1b4c20099293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e467cd530b4c19acc7309ae8f7faac",
            "placeholder": "​",
            "style": "IPY_MODEL_45d6c07961584a069b00a4c136ba09b6",
            "value": " 56.9M/56.9M [00:02&lt;00:00, 31.6MB/s]"
          }
        },
        "d5b4b49cc3db4a4ab6e7c4c58a6801e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "703b67c72033483b8c680b4e86895032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a56cfb45a04e938257adb3ae5194bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a999b0ad73a4e6e8946ed2ddc63ebe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c08a00709247dca674612bbc3f9d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40e467cd530b4c19acc7309ae8f7faac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d6c07961584a069b00a4c136ba09b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10891d7d202c4b6d8006aa14a12746c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c75cf9f81024312a02dcd87b6c5e660",
              "IPY_MODEL_f7f0b26713604a5da342812d8b249308",
              "IPY_MODEL_d8012e316e974b318b2d163151c9485a"
            ],
            "layout": "IPY_MODEL_061b940d66a44abb9717a62409723be0"
          }
        },
        "6c75cf9f81024312a02dcd87b6c5e660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7db5983e725446585aea8d7f84574ae",
            "placeholder": "​",
            "style": "IPY_MODEL_30c1fd74eaec44f2bc4e35ebda15a119",
            "value": "Extracting data files: 100%"
          }
        },
        "f7f0b26713604a5da342812d8b249308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd9fad3f124a4a88a43bc35d008ed95c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52c1cfd029094445bde62c030fc66249",
            "value": 2
          }
        },
        "d8012e316e974b318b2d163151c9485a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b6a9f4ab784e479edbca2d6990af5d",
            "placeholder": "​",
            "style": "IPY_MODEL_c717065afc9844eebfed962af5c5cd92",
            "value": " 2/2 [00:00&lt;00:00, 40.18it/s]"
          }
        },
        "061b940d66a44abb9717a62409723be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7db5983e725446585aea8d7f84574ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c1fd74eaec44f2bc4e35ebda15a119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd9fad3f124a4a88a43bc35d008ed95c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c1cfd029094445bde62c030fc66249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07b6a9f4ab784e479edbca2d6990af5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c717065afc9844eebfed962af5c5cd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af06bdc5e80f42068e8c89721bf77de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce15a98687934065a10c3cf290ee423f",
              "IPY_MODEL_7794be37848d465ba14e0a43102dbdbe",
              "IPY_MODEL_e88dc727f14e4672945d30daf6d91305"
            ],
            "layout": "IPY_MODEL_758d313479284982bc149705df95bbc9"
          }
        },
        "ce15a98687934065a10c3cf290ee423f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7244da34744f208be6b1a61448e612",
            "placeholder": "​",
            "style": "IPY_MODEL_269c0dec6fd64a10afdd54882ea8187a",
            "value": "Generating train split: "
          }
        },
        "7794be37848d465ba14e0a43102dbdbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32f3e153d154d6db4379d929c042fab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dc000fe6bbe472c9634296bbc3f8a7e",
            "value": 1
          }
        },
        "e88dc727f14e4672945d30daf6d91305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64173ea180994451bd1a5e104d2482ca",
            "placeholder": "​",
            "style": "IPY_MODEL_dabf5460bda647f6bbe3ff427fb6a204",
            "value": " 47452/0 [00:03&lt;00:00, 12631.34 examples/s]"
          }
        },
        "758d313479284982bc149705df95bbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8a7244da34744f208be6b1a61448e612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269c0dec6fd64a10afdd54882ea8187a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32f3e153d154d6db4379d929c042fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9dc000fe6bbe472c9634296bbc3f8a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64173ea180994451bd1a5e104d2482ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dabf5460bda647f6bbe3ff427fb6a204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42db29c6ffc54b33829e320ba4af0f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_818537cfead846489f2a76504c53b8f1",
              "IPY_MODEL_127d5f7a209e4b0ca1d70f5d9729d8c4",
              "IPY_MODEL_462fe956ee0a4ddf9d071ddebaef745f"
            ],
            "layout": "IPY_MODEL_a58853fb4dbc43e4b6bd517e26ae837a"
          }
        },
        "818537cfead846489f2a76504c53b8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d33d7f96e5948c6b818417b51436298",
            "placeholder": "​",
            "style": "IPY_MODEL_65f73ce42e254a52b9696777f9de834c",
            "value": "Generating test split: "
          }
        },
        "127d5f7a209e4b0ca1d70f5d9729d8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c65098aeef848159ef84539df41690b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b608708a774d4cf183221532e2cd5e79",
            "value": 1
          }
        },
        "462fe956ee0a4ddf9d071ddebaef745f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cff16048804c879fbf525b79f3dd45",
            "placeholder": "​",
            "style": "IPY_MODEL_628c910f7e064f40b44370f2f839aee9",
            "value": " 11864/0 [00:01&lt;00:00, 11791.72 examples/s]"
          }
        },
        "a58853fb4dbc43e4b6bd517e26ae837a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0d33d7f96e5948c6b818417b51436298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f73ce42e254a52b9696777f9de834c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c65098aeef848159ef84539df41690b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b608708a774d4cf183221532e2cd5e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64cff16048804c879fbf525b79f3dd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628c910f7e064f40b44370f2f839aee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}